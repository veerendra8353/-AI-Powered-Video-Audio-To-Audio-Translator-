{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg7QruhIa8Ep"
      },
      "source": [
        "# Speech-to-Speech Translation (Google Colab)\n",
        "\n",
        "This notebook runs a simple **video → speech → translation → TTS → final video** pipeline.\n",
        "\n",
        "## Steps\n",
        "1. Install dependencies\n",
        "2. Upload input video (`input_video.mp4`)\n",
        "3. Run the pipeline\n",
        "4. Download `translated_video.mp4`\n"
      ],
      "id": "lg7QruhIa8Ep"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RtFinJ4a8Ev",
        "outputId": "4c904cfb-de2f-4b45-d562-37bac4fe907b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.7.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio-client 1.14.0 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "google-adk 1.25.0 requires httpx<1.0.0,>=0.27.0, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 2.20.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "google-genai 1.63.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\n",
            "langgraph-sdk 0.3.5 requires httpx>=0.25.2, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio 5.50.0 requires httpx<1.0,>=0.24.1, but you have httpx 0.13.3 which is incompatible.\n",
            "mcp 1.26.0 requires httpx>=0.27.1, but you have httpx 0.13.3 which is incompatible.\n",
            "huggingface-hub 1.4.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once)\n",
        "!pip -q install moviepy speechrecognition googletrans==4.0.0-rc1 gtts pydub\n",
        "!apt-get -qq install -y ffmpeg\n"
      ],
      "id": "6RtFinJ4a8Ev"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "I9UtR5j9a8Ez",
        "outputId": "7481a952-8fa6-497b-9b38-ef6274cfd765"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3732f88b-dabe-4dfe-ad55-0a021366d3fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3732f88b-dabe-4dfe-ad55-0a021366d3fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4 to WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n"
          ]
        }
      ],
      "source": [
        "# Upload your input video and rename it to input_video.mp4\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "id": "I9UtR5j9a8Ez"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYI5celXa8E1",
        "outputId": "b3793994-7fc0-4921-cb92-e491adcf2b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the language code (e.g., hi, es, fr, te): te\n",
            "Using detected file: WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n",
            "Extracting audio from WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4...\n",
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converting speech to text...\n",
            "Recognized Text: do well in your life and you've achieved every material game that you want which you should please don't give up on that don't become a philosopher before you become rich\n",
            "Translating text to te...\n",
            "Translated Text: మీ జీవితంలో బాగా చేయండి మరియు మీరు కోరుకునే ప్రతి మెటీరియల్ గేమ్‌ను మీరు సాధించారు, దయచేసి మీరు దానిని వదులుకోవద్దు, మీరు ధనవంతులు కావడానికి ముందు తత్వవేత్తగా మారకండి\n",
            "Generating translated speech in te...\n",
            "Merging audio with video...\n",
            "Moviepy - Building video translated_video.mp4.\n",
            "MoviePy - Writing audio in translated_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video translated_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  98%|█████████▊| 261/265 [00:12<00:00, 23.41it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 262/265, at time 8.73/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t: 100%|█████████▉| 264/265 [00:12<00:00, 22.42it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 263/265, at time 8.77/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 264/265, at time 8.80/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready translated_video.mp4\n",
            "Done! Output: translated_video.mp4\n"
          ]
        }
      ],
      "source": [
        "import moviepy.editor as mp\n",
        "import speech_recognition as sr\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "def extract_audio(video_path, audio_path='extracted_audio.wav'):\n",
        "    print(f'Extracting audio from {video_path}...')\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    video.audio.write_audiofile(audio_path)\n",
        "    return audio_path\n",
        "\n",
        "def speech_to_text(audio_path):\n",
        "    print('Converting speech to text...')\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    text = recognizer.recognize_google(audio)\n",
        "    print('Recognized Text:', text)\n",
        "    return text\n",
        "\n",
        "def translate_text(text, target_lang='hi'):\n",
        "    print(f'Translating text to {target_lang}...')\n",
        "    translator = Translator()\n",
        "    translated = translator.translate(text, dest=target_lang)\n",
        "    print('Translated Text:', translated.text)\n",
        "    return translated.text\n",
        "\n",
        "def text_to_speech(text, lang='hi', output_audio='translated_audio.mp3'):\n",
        "    print(f'Generating translated speech in {lang}...')\n",
        "    # Basic mapping for common full names to codes\n",
        "    lang_map = {'telugu': 'te', 'hindi': 'hi', 'spanish': 'es', 'french': 'fr', 'tamil': 'ta'}\n",
        "    lang_code = lang_map.get(lang.lower(), lang)\n",
        "\n",
        "    tts = gTTS(text=text, lang=lang_code)\n",
        "    tts.save(output_audio)\n",
        "    return output_audio\n",
        "\n",
        "def merge_audio_video(video_path, audio_path, output_video='translated_video.mp4'):\n",
        "    print('Merging audio with video...')\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    new_audio = mp.AudioFileClip(audio_path)\n",
        "    if new_audio.duration > video.duration:\n",
        "        new_audio = new_audio.subclip(0, video.duration)\n",
        "    final_video = video.set_audio(new_audio)\n",
        "    final_video.write_videofile(output_video)\n",
        "    print('Done! Output:', output_video)\n",
        "\n",
        "def run_pipeline(video_file, target_language='hi'):\n",
        "    if not os.path.exists(video_file):\n",
        "        mp4_files = [f for f in os.listdir('.') if f.endswith('.mp4') and f != 'translated_video.mp4']\n",
        "        if mp4_files:\n",
        "            video_file = mp4_files[0]\n",
        "            print(f'Using detected file: {video_file}')\n",
        "        else:\n",
        "            print('Error: No video file found. Please upload an mp4 file.')\n",
        "            return\n",
        "\n",
        "    audio = extract_audio(video_file)\n",
        "    text = speech_to_text(audio)\n",
        "    translated = translate_text(text, target_language)\n",
        "    tts_audio = text_to_speech(translated, target_language)\n",
        "    merge_audio_video(video_file, tts_audio)\n",
        "\n",
        "# Prompt for language selection\n",
        "target_lang_input = input(\"Enter the language code (e.g., hi, es, fr, te): \")\n",
        "run_pipeline('input_video.mp4', target_lang_input)"
      ],
      "id": "SYI5celXa8E1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rvCPTkvia8E3",
        "outputId": "f958ed50-f013-40e5-f6c5-92eefb9f35bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78a0ed54-50e7-497f-a3ea-4be4c27d7e1f\", \"translated_video.mp4\", 1300890)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download the final video\n",
        "from google.colab import files\n",
        "files.download('translated_video.mp4')\n"
      ],
      "id": "rvCPTkvia8E3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "429565a9"
      },
      "source": [
        "# Task\n",
        "Update the video translation pipeline to support gender selection and a numeric menu-based input system. Modify the `text_to_speech` function to accept a gender parameter and provide a mechanism (like a note or specific voice mapping) for choosing between male and female voices. Implement a numeric menu using `input()` to allow the user to select the gender (1: Men, 2: Women) and the target language (1: Telugu, 2: Hindi, etc.). Finally, refactor the `run_pipeline` call to use these numeric inputs to process the video \"WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\" and produce the `translated_video.mp4`."
      ],
      "id": "429565a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fbdb993"
      },
      "source": [
        "## Update TTS for Gender Support\n",
        "\n",
        "### Subtask:\n",
        "Modify the `text_to_speech` function to accept a gender parameter and handle gender selection logic.\n"
      ],
      "id": "8fbdb993"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233926da"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the `text_to_speech` function to include the `gender` parameter and add the requested logic and documentation to support future expansion, as per the instructions.\n",
        "\n"
      ],
      "id": "233926da"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae8f025a",
        "outputId": "8ff6bd25-c8b5-4335-bd1e-f25a55a0b649"
      },
      "source": [
        "def text_to_speech(text, lang='hi', gender='female', output_audio='translated_audio.mp3'):\n",
        "    \"\"\"\n",
        "    Generates translated speech.\n",
        "\n",
        "    Note: gTTS natively defaults to a female-sounding voice. The 'gender' parameter\n",
        "    is integrated here to support future expansion with other TTS engines (like pyttsx3\n",
        "    or Cloud APIs) that support specific voice IDs.\n",
        "    \"\"\"\n",
        "    print(f'Generating translated speech in {lang}...')\n",
        "\n",
        "    # Acknowledge the selected gender for the pipeline\n",
        "    gender_map = {'male': '1', 'female': '2'}\n",
        "    selected_code = gender_map.get(gender.lower(), '2')\n",
        "    print(f'Selected Gender Logic: {gender} (ID: {selected_code})')\n",
        "\n",
        "    # Language mapping logic\n",
        "    lang_map = {'telugu': 'te', 'hindi': 'hi', 'spanish': 'es', 'french': 'fr', 'tamil': 'ta'}\n",
        "    lang_code = lang_map.get(lang.lower(), lang)\n",
        "\n",
        "    # Using gTTS for synthesis (defaulting to its standard voice)\n",
        "    tts = gTTS(text=text, lang=lang_code)\n",
        "    tts.save(output_audio)\n",
        "    return output_audio\n",
        "\n",
        "print('Updated text_to_speech function with gender support.')"
      ],
      "id": "ae8f025a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated text_to_speech function with gender support.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fce53868"
      },
      "source": [
        "## Create Menu-Based Input\n",
        "\n",
        "### Subtask:\n",
        "Implement a numeric menu system using `input()` to capture user preferences for gender and target language.\n"
      ],
      "id": "fce53868"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56cea6c6"
      },
      "source": [
        "**Reasoning**:\n",
        "I will implement a numeric menu-based input system using the `input()` function to capture and map user preferences for gender and target language to their respective internal values ('male'/'female' and language codes).\n",
        "\n"
      ],
      "id": "56cea6c6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a4b6a31",
        "outputId": "b9fe89ba-70bd-45a4-c6a4-86480cae8cad"
      },
      "source": [
        "def get_user_preferences():\n",
        "    # 1. Gender Selection Menu\n",
        "    print(\"\\n--- Select Gender ---\")\n",
        "    print(\"1: Men\")\n",
        "    print(\"2: Women\")\n",
        "    gender_choice = input(\"Enter your choice (1 or 2): \")\n",
        "\n",
        "    # 2. Language Selection Menu\n",
        "    print(\"\\n--- Select Target Language ---\")\n",
        "    print(\"1: Telugu\")\n",
        "    print(\"2: Hindi\")\n",
        "    print(\"3: Spanish\")\n",
        "    print(\"4: French\")\n",
        "    lang_choice = input(\"Enter your choice (1, 2, 3, or 4): \")\n",
        "\n",
        "    # 3. Logic to map gender choice\n",
        "    gender_map = {'1': 'male', '2': 'female'}\n",
        "    selected_gender = gender_map.get(gender_choice, 'female') # Default to female if invalid\n",
        "\n",
        "    # 4. Logic to map language choice\n",
        "    lang_map = {\n",
        "        '1': {'name': 'Telugu', 'code': 'te'},\n",
        "        '2': {'name': 'Hindi', 'code': 'hi'},\n",
        "        '3': {'name': 'Spanish', 'code': 'es'},\n",
        "        '4': {'name': 'French', 'code': 'fr'}\n",
        "    }\n",
        "    lang_info = lang_map.get(lang_choice, {'name': 'Hindi', 'code': 'hi'}) # Default to Hindi\n",
        "    selected_lang_code = lang_info['code']\n",
        "    selected_lang_name = lang_info['name']\n",
        "\n",
        "    # 5. Print resolved selections to verify\n",
        "    print(f\"\\nResolved Selections:\")\n",
        "    print(f\"Selected Language: {selected_lang_name} ({selected_lang_code})\")\n",
        "    print(f\"Selected Gender: {selected_gender}\")\n",
        "\n",
        "    return selected_lang_code, selected_gender\n",
        "\n",
        "# Execute the menu to capture input\n",
        "chosen_lang, chosen_gender = get_user_preferences()"
      ],
      "id": "7a4b6a31",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Select Gender ---\n",
            "1: Men\n",
            "2: Women\n",
            "Enter your choice (1 or 2): 1\n",
            "\n",
            "--- Select Target Language ---\n",
            "1: Telugu\n",
            "2: Hindi\n",
            "3: Spanish\n",
            "4: French\n",
            "Enter your choice (1, 2, 3, or 4): 1\n",
            "\n",
            "Resolved Selections:\n",
            "Selected Language: Telugu (te)\n",
            "Selected Gender: male\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b85e5d51"
      },
      "source": [
        "## Update Pipeline Integration\n",
        "\n",
        "### Subtask:\n",
        "Refactor the `run_pipeline` call and function to incorporate the new gender and language variables captured from the menu system.\n"
      ],
      "id": "b85e5d51"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22009a18"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the run_pipeline function to accept the gender parameter and call it with the previously captured variables to process the specific video file.\n",
        "\n"
      ],
      "id": "22009a18"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b0f153b",
        "outputId": "bd62bfb3-ef94-4d0d-ab4b-36d5c16e786b"
      },
      "source": [
        "def run_pipeline(video_file, target_language='hi', gender='female'):\n",
        "    \"\"\"\n",
        "    Updated pipeline to handle gender selection and specific video processing.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_file):\n",
        "        print(f'Error: File {video_file} not found.')\n",
        "        return\n",
        "\n",
        "    # 1. Extract Audio\n",
        "    audio = extract_audio(video_file)\n",
        "\n",
        "    # 2. Speech to Text\n",
        "    text = speech_to_text(audio)\n",
        "\n",
        "    # 3. Translate Text\n",
        "    translated = translate_text(text, target_language)\n",
        "\n",
        "    # 4. Text to Speech with Gender support\n",
        "    tts_audio = text_to_speech(translated, target_language, gender)\n",
        "\n",
        "    # 5. Merge Audio and Video\n",
        "    merge_audio_video(video_file, tts_audio)\n",
        "\n",
        "# Call the pipeline with variables from the menu system\n",
        "specific_video = 'WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4'\n",
        "print(f'\\nStarting pipeline for: {specific_video}')\n",
        "run_pipeline(specific_video, chosen_lang, chosen_gender)"
      ],
      "id": "0b0f153b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting pipeline for: WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n",
            "Extracting audio from WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4...\n",
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converting speech to text...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized Text: do well in your life and you've achieved every material game that you want which you should please don't give up on that don't become a philosopher before you become rich\n",
            "Translating text to te...\n",
            "Translated Text: మీ జీవితంలో బాగా చేయండి మరియు మీరు కోరుకునే ప్రతి మెటీరియల్ గేమ్‌ను మీరు సాధించారు, దయచేసి మీరు దానిని వదులుకోవద్దు, మీరు ధనవంతులు కావడానికి ముందు తత్వవేత్తగా మారకండి\n",
            "Generating translated speech in te...\n",
            "Selected Gender Logic: male (ID: 1)\n",
            "Merging audio with video...\n",
            "Moviepy - Building video translated_video.mp4.\n",
            "MoviePy - Writing audio in translated_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video translated_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  99%|█████████▉| 263/265 [00:09<00:00, 24.57it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 262/265, at time 8.73/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 263/265, at time 8.77/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 264/265, at time 8.80/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready translated_video.mp4\n",
            "Done! Output: translated_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "860fc41a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the run_pipeline function to accept the gender parameter and call it with the previously captured variables to process the specific video file.\n",
        "\n"
      ],
      "id": "860fc41a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f99c22c",
        "outputId": "2b0a393f-9b3d-414f-ca66-b7a82c542880"
      },
      "source": [
        "def run_pipeline(video_file, target_language='hi', gender='female'):\n",
        "    \"\"\"\n",
        "    Updated pipeline to handle gender selection and specific video processing.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_file):\n",
        "        print(f'Error: File {video_file} not found.')\n",
        "        return\n",
        "\n",
        "    # 1. Extract Audio\n",
        "    audio = extract_audio(video_file)\n",
        "\n",
        "    # 2. Speech to Text\n",
        "    text = speech_to_text(audio)\n",
        "\n",
        "    # 3. Translate Text\n",
        "    translated = translate_text(text, target_language)\n",
        "\n",
        "    # 4. Text to Speech with Gender support\n",
        "    tts_audio = text_to_speech(translated, target_language, gender)\n",
        "\n",
        "    # 5. Merge Audio and Video\n",
        "    merge_audio_video(video_file, tts_audio)\n",
        "\n",
        "# Call the pipeline with variables from the menu system\n",
        "specific_video = 'WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4'\n",
        "print(f'\\nStarting pipeline for: {specific_video}')\n",
        "run_pipeline(specific_video, chosen_lang, chosen_gender)"
      ],
      "id": "1f99c22c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting pipeline for: WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n",
            "Extracting audio from WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4...\n",
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converting speech to text...\n",
            "Recognized Text: do well in your life and you've achieved every material game that you want which you should please don't give up on that don't become a philosopher before you become rich\n",
            "Translating text to te...\n",
            "Translated Text: మీ జీవితంలో బాగా చేయండి మరియు మీరు కోరుకునే ప్రతి మెటీరియల్ గేమ్‌ను మీరు సాధించారు, దయచేసి మీరు దానిని వదులుకోవద్దు, మీరు ధనవంతులు కావడానికి ముందు తత్వవేత్తగా మారకండి\n",
            "Generating translated speech in te...\n",
            "Selected Gender Logic: male (ID: 1)\n",
            "Merging audio with video...\n",
            "Moviepy - Building video translated_video.mp4.\n",
            "MoviePy - Writing audio in translated_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video translated_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  98%|█████████▊| 261/265 [00:09<00:00, 15.38it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 262/265, at time 8.73/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t: 100%|█████████▉| 264/265 [00:09<00:00, 14.85it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 263/265, at time 8.77/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 264/265, at time 8.80/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready translated_video.mp4\n",
            "Done! Output: translated_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29266dfd"
      },
      "source": [
        "# Task\n",
        "Update the video translation pipeline to support gender selection and a numeric menu-based input system. Modify the `text_to_speech` function to accept a `gender` parameter and include logic to handle choices between male and female voices. Implement a numeric menu using `input()` that allows selecting a gender (1: Men, 2: Women) and a target language (1: Telugu, 2: Hindi, 3: English, 4: Tamil, 5: Spanish, 6: Kannada). Finally, refactor the `run_pipeline` call to use these selections to process the video \"WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\" and generate the final output file \"translated_video.mp4\"."
      ],
      "id": "29266dfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b3e7aa3"
      },
      "source": [
        "## Configure TTS for Gender Handling\n",
        "\n",
        "### Subtask:\n",
        "Modify the `text_to_speech` function to accept a `gender` parameter and include logic to handle choices between male and female voices.\n"
      ],
      "id": "5b3e7aa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa52564a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will redefine the text_to_speech function to include the gender parameter and the requested logic as specified in the subtask instructions.\n",
        "\n"
      ],
      "id": "aa52564a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca21bd7a",
        "outputId": "f7d6f102-abf0-4d7c-bcc8-26e74b43bd0b"
      },
      "source": [
        "def text_to_speech(text, lang='hi', gender='female', output_audio='translated_audio.mp3'):\n",
        "    \"\"\"\n",
        "    Generates translated speech with a specified language and gender preference.\n",
        "    \"\"\"\n",
        "    print(f'Generating translated speech in {lang}...')\n",
        "\n",
        "    # Logic to handle/acknowledge the selected gender for simulation\n",
        "    # Note: gTTS typically uses a single default voice per language.\n",
        "    print(f'Selected Voice Gender: {gender}')\n",
        "\n",
        "    # Language mapping logic\n",
        "    lang_map = {'telugu': 'te', 'hindi': 'hi', 'spanish': 'es', 'french': 'fr', 'tamil': 'ta'}\n",
        "    lang_code = lang_map.get(lang.lower(), lang)\n",
        "\n",
        "    # Synthesis using gTTS\n",
        "    tts = gTTS(text=text, lang=lang_code)\n",
        "    tts.save(output_audio)\n",
        "\n",
        "    return output_audio\n",
        "\n",
        "print('Function text_to_speech updated successfully.')"
      ],
      "id": "ca21bd7a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function text_to_speech updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a816c1dc"
      },
      "source": [
        "## Execute Numeric Selection Menu\n",
        "\n",
        "### Subtask:\n",
        "Implement and run a numeric menu system to capture user preferences for gender and target language.\n"
      ],
      "id": "a816c1dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7044e34"
      },
      "source": [
        "**Reasoning**:\n",
        "I will implement a numeric menu-based input system using `input()` to capture user preferences for gender and target language, and then map those selections to the corresponding internal values.\n",
        "\n"
      ],
      "id": "e7044e34"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6516bdb6",
        "outputId": "d694666d-fe67-42a1-c891-71c7d935ae6c"
      },
      "source": [
        "def get_numeric_preferences():\n",
        "    # 1. Gender Selection Menu\n",
        "    print(\"\\n--- Select Gender ---\")\n",
        "    print(\"1: Men (male)\")\n",
        "    print(\"2: Women (female)\")\n",
        "    gender_choice = input(\"Enter your choice (1 or 2): \")\n",
        "\n",
        "    # 2. Language Selection Menu\n",
        "    print(\"\\n--- Select Target Language ---\")\n",
        "    print(\"1: Telugu (te)\")\n",
        "    print(\"2: Hindi (hi)\")\n",
        "    print(\"3: English (en)\")\n",
        "    print(\"4: Tamil (ta)\")\n",
        "    print(\"5: Spanish (es)\")\n",
        "    print(\"6: Kannada (kn)\")\n",
        "    lang_choice = input(\"Enter your choice (1-6): \")\n",
        "\n",
        "    # 3. Mapping Logic\n",
        "    gender_map = {'1': 'male', '2': 'female'}\n",
        "    selected_gender = gender_map.get(gender_choice, 'female') # Default to female\n",
        "\n",
        "    lang_map = {\n",
        "        '1': 'te',\n",
        "        '2': 'hi',\n",
        "        '3': 'en',\n",
        "        '4': 'ta',\n",
        "        '5': 'es',\n",
        "        '6': 'kn'\n",
        "    }\n",
        "    selected_lang = lang_map.get(lang_choice, 'hi') # Default to Hindi\n",
        "\n",
        "    # 4. Print resolved selections\n",
        "    print(f\"\\nResolved Selections:\")\n",
        "    print(f\"Selected Gender: {selected_gender}\")\n",
        "    print(f\"Selected Language Code: {selected_lang}\")\n",
        "\n",
        "    return selected_lang, selected_gender\n",
        "\n",
        "# Execute to capture input for the next steps\n",
        "chosen_lang, chosen_gender = get_numeric_preferences()"
      ],
      "id": "6516bdb6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Select Gender ---\n",
            "1: Men (male)\n",
            "2: Women (female)\n",
            "Enter your choice (1 or 2): 1\n",
            "\n",
            "--- Select Target Language ---\n",
            "1: Telugu (te)\n",
            "2: Hindi (hi)\n",
            "3: English (en)\n",
            "4: Tamil (ta)\n",
            "5: Spanish (es)\n",
            "6: Kannada (kn)\n",
            "Enter your choice (1-6): 1\n",
            "\n",
            "Resolved Selections:\n",
            "Selected Gender: male\n",
            "Selected Language Code: te\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "138d8a12"
      },
      "source": [
        "## Process Video Pipeline\n",
        "\n",
        "### Subtask:\n",
        "Re-run the `run_pipeline` function using your selections to process 'WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4' and generate the 'translated_video.mp4'.\n"
      ],
      "id": "138d8a12"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a3853b9"
      },
      "source": [
        "**Reasoning**:\n",
        "I will re-run the run_pipeline function using the variables captured from the numeric menu to process the specified video file and generate the translated output.\n",
        "\n"
      ],
      "id": "7a3853b9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9514443",
        "outputId": "a663c1a9-36df-4480-c1d6-80a912c1107b"
      },
      "source": [
        "def run_pipeline(video_file, target_language='hi', gender='female'):\n",
        "    \"\"\"\n",
        "    Executes the translation pipeline using specific video, language, and gender parameters.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_file):\n",
        "        print(f'Error: File {video_file} not found.')\n",
        "        return\n",
        "\n",
        "    # 1. Extract Audio\n",
        "    audio = extract_audio(video_file)\n",
        "\n",
        "    # 2. Speech to Text\n",
        "    text = speech_to_text(audio)\n",
        "\n",
        "    # 3. Translate Text\n",
        "    translated = translate_text(text, target_language)\n",
        "\n",
        "    # 4. Text to Speech with the specific gender parameter\n",
        "    tts_audio = text_to_speech(translated, target_language, gender)\n",
        "\n",
        "    # 5. Merge Audio and Video\n",
        "    merge_audio_video(video_file, tts_audio, output_video='translated_video.mp4')\n",
        "\n",
        "# Call the pipeline with the specific video and the variables from the menu selection\n",
        "specific_video = 'WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4'\n",
        "print(f'\\nStarting pipeline for: {specific_video}')\n",
        "run_pipeline(specific_video, chosen_lang, chosen_gender)\n",
        "print('\\nPipeline execution complete. File \"translated_video.mp4\" should be generated.')"
      ],
      "id": "e9514443",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting pipeline for: WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n",
            "Extracting audio from WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4...\n",
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converting speech to text...\n",
            "Recognized Text: do well in your life and you've achieved every material game that you want which you should please don't give up on that don't become a philosopher before you become rich\n",
            "Translating text to te...\n",
            "Translated Text: మీ జీవితంలో బాగా చేయండి మరియు మీరు కోరుకునే ప్రతి మెటీరియల్ గేమ్‌ను మీరు సాధించారు, దయచేసి మీరు దానిని వదులుకోవద్దు, మీరు ధనవంతులు కావడానికి ముందు తత్వవేత్తగా మారకండి\n",
            "Generating translated speech in te...\n",
            "Selected Voice Gender: male\n",
            "Merging audio with video...\n",
            "Moviepy - Building video translated_video.mp4.\n",
            "MoviePy - Writing audio in translated_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video translated_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  99%|█████████▉| 263/265 [00:09<00:00, 15.95it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 262/265, at time 8.73/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 263/265, at time 8.77/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t: 100%|██████████| 265/265 [00:09<00:00, 15.77it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 264/265, at time 8.80/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready translated_video.mp4\n",
            "Done! Output: translated_video.mp4\n",
            "\n",
            "Pipeline execution complete. File \"translated_video.mp4\" should be generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95d5ca55"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully implemented the refined run_pipeline function and executed the translation process. I will now add this block to the notebook as the final step of the subtask to process the video with the user-selected preferences.\n",
        "\n"
      ],
      "id": "95d5ca55"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a041ac17",
        "outputId": "cbb460ba-9f89-42b0-948d-7c3e9fbe3982"
      },
      "source": [
        "def run_pipeline(video_file, target_language='hi', gender='female'):\n",
        "    \"\"\"\n",
        "    Executes the translation pipeline using specific video, language, and gender parameters.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_file):\n",
        "        print(f'Error: File {video_file} not found.')\n",
        "        return\n",
        "\n",
        "    # 1. Extract Audio\n",
        "    audio = extract_audio(video_file)\n",
        "\n",
        "    # 2. Speech to Text\n",
        "    text = speech_to_text(audio)\n",
        "\n",
        "    # 3. Translate Text\n",
        "    translated = translate_text(text, target_language)\n",
        "\n",
        "    # 4. Text to Speech with the specific gender parameter\n",
        "    tts_audio = text_to_speech(translated, target_language, gender)\n",
        "\n",
        "    # 5. Merge Audio and Video\n",
        "    merge_audio_video(video_file, tts_audio, output_video='translated_video.mp4')\n",
        "\n",
        "# Call the pipeline with the specific video and the variables from the menu selection\n",
        "specific_video = 'WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4'\n",
        "print(f'\\nStarting pipeline for: {specific_video}')\n",
        "run_pipeline(specific_video, chosen_lang, chosen_gender)\n",
        "print('\\nPipeline execution complete. File \"translated_video.mp4\" should be generated.')"
      ],
      "id": "a041ac17",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting pipeline for: WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n",
            "Extracting audio from WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4...\n",
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converting speech to text...\n",
            "Recognized Text: do well in your life and you've achieved every material game that you want which you should please don't give up on that don't become a philosopher before you become rich\n",
            "Translating text to te...\n",
            "Translated Text: మీ జీవితంలో బాగా చేయండి మరియు మీరు కోరుకునే ప్రతి మెటీరియల్ గేమ్‌ను మీరు సాధించారు, దయచేసి మీరు దానిని వదులుకోవద్దు, మీరు ధనవంతులు కావడానికి ముందు తత్వవేత్తగా మారకండి\n",
            "Generating translated speech in te...\n",
            "Selected Voice Gender: male\n",
            "Merging audio with video...\n",
            "Moviepy - Building video translated_video.mp4.\n",
            "MoviePy - Writing audio in translated_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video translated_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  99%|█████████▉| 263/265 [00:09<00:00, 25.74it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 262/265, at time 8.73/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 263/265, at time 8.77/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 264/265, at time 8.80/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready translated_video.mp4\n",
            "Done! Output: translated_video.mp4\n",
            "\n",
            "Pipeline execution complete. File \"translated_video.mp4\" should be generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2713a465"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully implemented the refined run_pipeline function and executed the translation process. I will now add this block to the notebook as the final step of the subtask to process the video with the user-selected preferences.\n",
        "\n"
      ],
      "id": "2713a465"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a8f4bfd",
        "outputId": "5ef831c9-4a14-471b-ea12-6941274bf48d"
      },
      "source": [
        "def run_pipeline(video_file, target_language='hi', gender='female'):\n",
        "    \"\"\"\n",
        "    Executes the translation pipeline using specific video, language, and gender parameters.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(video_file):\n",
        "        print(f'Error: File {video_file} not found.')\n",
        "        return\n",
        "\n",
        "    # 1. Extract Audio\n",
        "    audio = extract_audio(video_file)\n",
        "\n",
        "    # 2. Speech to Text\n",
        "    text = speech_to_text(audio)\n",
        "\n",
        "    # 3. Translate Text\n",
        "    translated = translate_text(text, target_language)\n",
        "\n",
        "    # 4. Text to Speech with the specific gender parameter\n",
        "    tts_audio = text_to_speech(translated, target_language, gender)\n",
        "\n",
        "    # 5. Merge Audio and Video\n",
        "    merge_audio_video(video_file, tts_audio, output_video='translated_video.mp4')\n",
        "\n",
        "# Call the pipeline with the specific video and the variables from the menu selection\n",
        "specific_video = 'WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4'\n",
        "print(f'\\nStarting pipeline for: {specific_video}')\n",
        "run_pipeline(specific_video, chosen_lang, chosen_gender)\n",
        "print('\\nPipeline execution complete. File \"translated_video.mp4\" should be generated.')"
      ],
      "id": "3a8f4bfd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting pipeline for: WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4\n",
            "Extracting audio from WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4...\n",
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Converting speech to text...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized Text: do well in your life and you've achieved every material game that you want which you should please don't give up on that don't become a philosopher before you become rich\n",
            "Translating text to te...\n",
            "Translated Text: మీ జీవితంలో బాగా చేయండి మరియు మీరు కోరుకునే ప్రతి మెటీరియల్ గేమ్‌ను మీరు సాధించారు, దయచేసి మీరు దానిని వదులుకోవద్దు, మీరు ధనవంతులు కావడానికి ముందు తత్వవేత్తగా మారకండి\n",
            "Generating translated speech in te...\n",
            "Selected Voice Gender: male\n",
            "Merging audio with video...\n",
            "Moviepy - Building video translated_video.mp4.\n",
            "MoviePy - Writing audio in translated_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video translated_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  98%|█████████▊| 260/265 [00:10<00:00, 22.98it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 262/265, at time 8.73/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "t: 100%|█████████▉| 264/265 [00:10<00:00, 23.42it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 263/265, at time 8.77/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file WhatsApp Video 2026-02-18 at 9.18.28 PM.mp4, 2764800 bytes wanted but 0 bytes read,at frame 264/265, at time 8.80/8.82 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready translated_video.mp4\n",
            "Done! Output: translated_video.mp4\n",
            "\n",
            "Pipeline execution complete. File \"translated_video.mp4\" should be generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcf2b2c4"
      },
      "source": [
        "# Task\n",
        "Download the final translated video \"translated_video.mp4\" to your local machine using `google.colab.files.download`."
      ],
      "id": "dcf2b2c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5df26104"
      },
      "source": [
        "## Download Translated Video\n",
        "\n",
        "### Subtask:\n",
        "Prompt the user to download the final translated video file from the Colab environment to their local machine.\n"
      ],
      "id": "5df26104"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6e35cbb"
      },
      "source": [
        "**Reasoning**:\n",
        "I will add a code cell to initiate the download of the 'translated_video.mp4' file from the Google Colab environment using the files.download() method.\n",
        "\n"
      ],
      "id": "b6e35cbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "e7206ea7",
        "outputId": "0786631d-80ee-49b4-ffb3-2a170772480b"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Initiate the download of the translated video\n",
        "print('Downloading translated_video.mp4...')\n",
        "files.download('translated_video.mp4')"
      ],
      "id": "e7206ea7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading translated_video.mp4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7005431b-f725-49d1-881b-d983350568ee\", \"translated_video.mp4\", 1300890)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4036d0e5"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the download process for 'translated_video.mp4' has been initiated and verify the completion of the task.\n"
      ],
      "id": "4036d0e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0d91dc0"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**How was the translated video transferred to the local machine?**\n",
        "The file `translated_video.mp4` was transferred by using the `google.colab.files.download` function, which triggers a native browser download prompt from the Colab environment.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "* **Module Utilization**: The process successfully utilized the `google.colab` library to bridge the gap between the cloud-based file system and the local environment.\n",
        "* **Execution Verification**: The system output confirmed that the download process for `translated_video.mp4` was initiated successfully following the completion of any prior video processing steps.\n",
        "* **User Interface Interaction**: The script effectively generated the necessary JavaScript triggers required for the browser to handle the file transfer.\n",
        "\n",
        "### Insights or Next Steps\n",
        "* **Verification**: Ensure the downloaded file size matches the processed version on the server to confirm no data corruption occurred during the transfer.\n",
        "* **Automation**: For future workflows involving multiple files, consider zipping assets before calling the download function to streamline the local saving process.\n"
      ],
      "id": "f0d91dc0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}